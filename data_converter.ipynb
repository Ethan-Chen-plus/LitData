{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43727aa-c732-4ef4-82e4-15300027d361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec65008-6dce-4b07-a246-7cca83541b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=读取./raw下的所有csv文件\n",
    "print 列名\n",
    "如果该列列名有功能段，则作为target，然后另外一列非Title的作为input，按照gpt微调格式填充：\n",
    "<s>Human: Write the '$文件名（去除后缀）' with the information below:{input} </s><s>Assistant: {target} </s>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65e4bd2d-c9a7-4053-b6b9-92968e9126ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: research design.csv, Columns: ['Title', 'Research Desgin 研究设计功能段', 'research design']\n",
      "File: transition_background.csv, Columns: ['Title', 'Transition I 背景类过渡段', 'Background information']\n",
      "File: research findings.csv, Columns: ['Title', 'Research Finding 研究发现功能段', 'Findings']\n",
      "File: transition program.csv, Columns: ['Unnamed: 0', 'Title', 'Transition II 项目类过渡段', 'program information']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the directory containing the raw CSV files\n",
    "raw_dir_path = './raw'\n",
    "clean_dir_path = './clean'\n",
    "\n",
    "# Ensure the clean directory exists\n",
    "os.makedirs(clean_dir_path, exist_ok=True)\n",
    "\n",
    "# Iterate over each file in the raw directory\n",
    "for filename in os.listdir(raw_dir_path):\n",
    "    # Check if the file is a CSV file\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read the CSV file\n",
    "        file_path = os.path.join(raw_dir_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Print column names\n",
    "        print(f\"File: {filename}, Columns: {df.columns.tolist()}\")\n",
    "\n",
    "        # Identify the target and input columns\n",
    "        target_column = None\n",
    "        input_column = None\n",
    "        for column in df.columns:\n",
    "            if \"过渡段\" in column or \"功能段\" in column:\n",
    "                target_column = column\n",
    "            elif column.lower() != \"title\":\n",
    "                input_column = column\n",
    "\n",
    "        # If target and input columns are identified, proceed with formatting\n",
    "        if target_column and input_column:\n",
    "            # Create a new DataFrame for the clean data\n",
    "            clean_df = pd.DataFrame({\n",
    "                \"text\": f\"<s>Human: Write the '{filename.replace('.csv', '')}' with the information below:\" + df[input_column] + \" </s><s>Assistant: \" + df[target_column].astype(str) + \" </s>\"\n",
    "            })\n",
    "\n",
    "            # Write the clean DataFrame to a new CSV file in the clean directory\n",
    "            clean_file_path = os.path.join(clean_dir_path, filename)\n",
    "            clean_df.to_csv(clean_file_path, index=False)\n",
    "        else:\n",
    "            print(f\"Could not identify target and input columns for file: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ada848-78a8-4fe0-bc69-d2fefad57b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=读取./clean下的所有csv文件\n",
    "对每列所有数据，如果数据的字符串中有'Identification_strategy'，则用replace方法替换为''\n",
    "同时，去除字符串中的6:这种数字+:的内容。\n",
    "写入./clean_again下的csv文件，各自保存\n",
    "然后将csv合并。写入final.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2649b63b-18ab-4da6-8b12-ecc40d34922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# 确保输出目录存在\n",
    "output_dir = './clean_again'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# 读取./clean目录下的所有csv文件\n",
    "csv_files = [f for f in os.listdir('./clean') if f.endswith('.csv')]\n",
    "\n",
    "# 初始化一个空的DataFrame来存储最终合并的数据\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for file in csv_files:\n",
    "    # 读取每个CSV文件\n",
    "    df = pd.read_csv(os.path.join('./clean', file))\n",
    "    \n",
    "    # 对DataFrame的每个元素应用替换规则\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].astype(str).apply(lambda x: x.replace('Identification_strategy', ''))\n",
    "        df[col] = df[col].apply(lambda x: re.sub(r'\\d+:', '', x))\n",
    "        df[col] = df[col].apply(lambda x: re.sub(r'\\d+：', '', x))\n",
    "    \n",
    "    # 保存处理后的文件\n",
    "    df.to_csv(os.path.join(output_dir, file), index=False)\n",
    "    \n",
    "    # 累加到最终的DataFrame\n",
    "    final_df = pd.concat([final_df, df], ignore_index=True)\n",
    "\n",
    "# 将合并后的DataFrame保存为final.csv\n",
    "final_df.to_csv('final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b5d63c4-8cf1-476b-bcf0-65ce66bbac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取final.csv文件\n",
    "df = pd.read_csv('final.csv')\n",
    "\n",
    "# 删除包含NaN值的行\n",
    "df = df.dropna()\n",
    "\n",
    "# 将结果写回到同一文件\n",
    "df.to_csv('final_new.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2696234-ad86-4901-8b56-d9aa17618ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Identification_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2137e2d-863a-4193-9ec3-4a59eb1bffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=df.iloc[10]['program information']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9986dbf6-e40d-4e2d-a6be-2da33fd90cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Program name\": Defense Meteorological Satellite Program (DMSP)\\n\"Enforcer\": Not specified\\n\"Beginning date\": 1992\\n\"Main purpose\": Originally designed to detect clouds for short-term Air Force weather forecasts\\n\"Development stage\": No longer in operation, data stopped in 2013\\n\\n\"Program name\": Visible Infrared Imaging Radiometer Suite (VIIRS)\\n\"Enforcer\": Not specified\\n\"Beginning date\": Not specified\\n\"Main purpose\": Consistently measure the radiance of light coming from earth, with high spatial accuracy and temporally comparable data\\n\"Development stage\": Currently in use, with monthly data available\\n\\n\"Program name\": Night lights data\\n\"Enforcer\": Not specified\\n\"Beginning date\": Not specified\\n\"Main purpose\": Proxy for local economic activity, particularly in poor countries\\n\"Development stage\": Widely used in economics, with over 150 studies utilizing night lights data\\n\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdbc9ecd-ccb7-484f-8ae3-76f5fc3f6fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program name\"\n",
      "Enforcer\"\n",
      "Beginning date\"\n",
      "Main purpose\"\n",
      "Development stage\"\n",
      "Program name\"\n",
      "Enforcer\"\n",
      "Beginning date\"\n",
      "Main purpose\"\n",
      "Development stage\"\n",
      "Program name\"\n",
      "Enforcer\"\n",
      "Beginning date\"\n",
      "Main purpose\"\n",
      "Development stage\"\n"
     ]
    }
   ],
   "source": [
    "# Split the original text by \":\", then for each segment, isolate the phrase immediately preceding the \":\".\n",
    "# This time, we need to ensure that phrases like \"Enforcer\" and \"Main purpose\" are correctly extracted as separate phrases.\n",
    "\n",
    "# Define a function to correct and isolate phrases accurately\n",
    "def correct_and_isolate_phrases(text):\n",
    "    phrases = []  # List to hold the corrected phrases\n",
    "    # Split the text by \":\", to get segments containing the phrases of interest\n",
    "    segments = text.split(\":\")\n",
    "    \n",
    "    for segment in segments[:-1]:  # Exclude the last segment as it doesn't precede a colon\n",
    "        # Attempt to isolate the phrase by finding the last occurrence of certain keywords or capital letters\n",
    "        # that typically start a phrase of interest\n",
    "        potential_starts = [segment.rfind(\"Program\"), segment.rfind(\"Enforcer\"), segment.rfind(\"Beginning\"), segment.rfind(\"Main\"), segment.rfind(\"Development\"), segment.rfind(\"Other\")]\n",
    "        # Filter out -1's (indicating no match) and find the maximum index to ensure we start from the latest possible point\n",
    "        start_index = max([index for index in potential_starts if index != -1])\n",
    "        if start_index != -1:\n",
    "            # Extract the phrase from the start index to the end of the segment\n",
    "            phrases.append(segment[start_index:].strip())\n",
    "        else:\n",
    "            # If no specific start is found, append the whole segment as a fallback\n",
    "            phrases.append(segment.strip())\n",
    "    \n",
    "    return phrases\n",
    "\n",
    "# Use the function to correct and isolate phrases from the text\n",
    "corrected_phrases = correct_and_isolate_phrases(text)\n",
    "\n",
    "# Join the corrected phrases with a newline character\n",
    "formatted_text_final = \"\\n\".join(corrected_phrases)\n",
    "\n",
    "print(formatted_text_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2144ab1f-4eb9-4639-b852-e64389920196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s>Human: Write the 'transition program' with the information below:Program name: United States Acid Rain Program (ARP)Enforcer: Environmental Protection Agency (EPA)Beginning date: 1995Main purpose: To control sulfur dioxide (SO2) emissions and reduce particulate matter smaller than 2.5 micrometers (PM2.5) pollution.Development stage: Implemented and enforced.Other information: The ARP created an immediate and persistent drop in SO2 emissions, allowing for an event study analysis to explore dynamic effects. The program regulated only certain SO2-intensive coal plants, comparing changes in mortality over time in counties most impacted by pollution from regulated plants to changes in mortality in counties with little to no related exposure. The program aimed to mitigate bias from national trends changing over time independent of pollution from coal-fired plants. The ARP generated limited economic spillovers and had negligible effects on income, employment, or migration. The program's effects on mortality rates suggest that reductions in long-term pollution concentrations contributed to declining mortality rates. </s><s>Assistant: 2：\\r\\nIn this paper, we estimate the effects of long-run pollution exposure on mortality by exploiting the United States Acid Rain Program (ARP), a cap-and-trade regulation to control sulfur dioxide (SO2) emissions, which avoids many of the issues associated with identifying long-run effects. First, the ARP created an immediate and persistent drop in SO2, a precursor gas in the formation of particulate matter smaller than 2.5 micrometers (PM2.5)1; PM2.5 is a pollutant with detrimental effects on human health (see Environmental Protection Agency (2004) for a comprehensive review). This one-time drop in pollution allows for an event study analysis to explore dynamic effects.\\r\\n3:\\r\\nSecond, the ARP regulated only certain SO2-intensive coal plants. This lends to a design comparing changes in mortality over time in counties most impacted by pollution from regulated plants to changes in mortality in counties with little to no related exposure. This mitigates bias from national trends changing over time independent of pollution from coal-fired plants, such as business cycles, health care access, and technological advances.\\r\\n4：\\r\\nThird, the vast distance both SO2 and PM2.5 travel once airborne subsumes many potential confounding general equilibrium?effects. Households sorting in response to the economic effects of the ARP will not bias estimates if such sorting remains within the effective range of pollution transport from a given region.2 Given existing evidence that finds such changes in housing amenity values occur at distances of less than 2 miles, long-distance residential sorting is likely to be limited.\\r\\n5：Fourth, the ARP generated limited economic spillovers. While many environmental regulations often lead to job loss (Greenstone, 2002; Walker, 2013), which can have independent effects on health (Sullivan and von Wachter, 2009), this issue is less relevant to the ARP as compliance costs and economic effects were low (Schmalensee and Stavins, 2017).4 Moreover, the broad spread of emissions beyond plants themselves subsumes local economic effects, to the extent they exist, in the same way they deal with sorting. We verify the ARP had negligible effects on income, employment, or migration, suggesting economic effects are unlikely to bias estimates of health effects. </s>\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.iloc[1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15d0830-4e40-40d5-a89c-a541d1486fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  \\\n",
      "0  Exposure to collective gender-based violence c...   \n",
      "1  Live tutoring calls did not improve learning d...   \n",
      "2  Manufacturing employment and women’s agency: E...   \n",
      "3  Social and financial incentives for overcoming...   \n",
      "4  The political impacts of land expropriation in...   \n",
      "\n",
      "                                 Transition I 背景类过渡段  \\\n",
      "0  3：\\nThis paper studies the causal long-run imp...   \n",
      "1  2:\\nTo keep students engaged and learning duri...   \n",
      "2  2：\\nThe paper contributes to the sparse litera...   \n",
      "3  2：\\nSince these pathogens are communicable, a ...   \n",
      "4  2:\\nState expropriation is generally justified...   \n",
      "\n",
      "                              Background information  \n",
      "0  \"1\": \"Globally, one in three women experience ...  \n",
      "1  \"1\": \"School closures due to the COVID-19 pand...  \n",
      "2  \"1\": \"The paper examines the impact of women's...  \n",
      "3  \"1\": \"Open defecation is practiced by one bill...  \n",
      "4  \"1\": \"State expropriation is common in human h...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv('./raw/transition background.csv')\n",
    "\n",
    "# 剔除 'Research Finding 研究发现功能段' 列\n",
    "df.drop(columns=['Research Finding 研究发现功能段'], inplace=True)\n",
    "\n",
    "# 打印剩余的列\n",
    "print(df.head())\n",
    "\n",
    "# 如果需要保存剔除列后的结果到新的CSV文件，可以使用以下代码\n",
    "df.to_csv('./raw/new_transition_background.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700bea65-f7fa-4983-b49b-1d2baa6c01fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rwkv)",
   "language": "python",
   "name": "rwkv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
